# %%
import pandas as pd
import numpy as np
import nx_tools as nt
import networkx as nx
from networkx.drawing.nx_pydot import graphviz_layout
import glob, re, json, os

PROJECT_PATH = r'D:\æ–°å®‰\2022 ç¶²è·¯é—œè¯'
PATH_PLY_MAIN = r'D:\æ–°å®‰\data\ml_2021\ml_ply_mix.txt'
PATH_PLY_MAIN_ALL = r'D:\æ–°å®‰\data\è¨‚å–®æ•´åˆè³‡æ–™\car_policy_full.txt'

DIR_HTH = r'D:\æ–°å®‰\data\HTH\hth_policy'
DIR_CAR = r'D:\æ–°å®‰\data\CAR'

path_hth = glob.glob(DIR_HTH + '\*\ht_ply_member_ins.txt')
path_hth_ply = glob.glob(DIR_HTH + '\*\ht_policy.txt')
path_car_ply = glob.glob(DIR_CAR + '\*\*\policy.txt')
path_car_iins = glob.glob(DIR_CAR + '\*\*\ply_ins_type.txt')

PATH_HTH_CODE = r'D:\æ–°å®‰\data\ä»£ç¢¼\HTH_éšªç¨®ä»£ç¢¼.csv'
PATH_CAR_CODE_LV1 = r'D:\æ–°å®‰\data\ä»£ç¢¼\car_code_iinsType.json'
PATH_CAR_CODE_LV2 = r'D:\æ–°å®‰\data\ä»£ç¢¼\car_code_iinsType_detail.json'

PATH_PROFILE = r'D:\æ–°å®‰\2022 å®¢æˆ¶åˆ†ç¾¤\data\features.parq'
DIR_NODES_SAVED = r'D:\æ–°å®‰\2022 ç¶²è·¯é—œè¯\2022 é—œè¯å®¢æˆ¶\data'

# %%

path_ply, path_iins = path_car_ply, path_car_iins
paths = path_car_ply
year = 2021
def load_data(paths, year, usecols = [], sep = '|'):
	filter_paths = [p for p in paths if re.match(f'.*{year}.*', p)]
	data = []
	for p in filter_paths:
		if usecols:
			data.append(pd.read_csv(p, sep = sep, dtype = str, usecols = usecols))
		else:
			data.append(pd.read_csv(p, sep = sep, dtype = str))
	return pd.concat(data)

def load_car_data(paths_ply, paths_iins, year, **kwargs):
	ply = load_data(paths_ply, year, usecols = ['ipolicy', 'fassured', 'iassured', 'iapplicant', 'itag'], **kwargs)
	iins = load_data(path_car_iins, year, usecols = ['ipolicy', 'iins_type', 'mins_premium'], **kwargs)
	m = iins.merge(ply, on = 'ipolicy', how = 'left')
	m = m.assign(mins_premium = lambda x: pd.to_numeric(x['mins_premium'], errors = 'ignore'))
	m = m.query("fassured == '1' & mins_premium > 0")
	with open(PATH_CAR_CODE_LV1, 'r', encoding = 'utf-8') as f:
		iins_mapper_lv1 = json.load(f)
	with open(PATH_CAR_CODE_LV2, 'r', encoding = 'utf-8') as f:
		iins_mapper_lv2 = json.load(f)
	m = m.assign(iins_type_name = lambda x: x['iins_type'].apply(lambda i: iins_mapper_lv1.get(i)),
				 iins_type_name_detail = lambda x: x['iins_type'].apply(lambda i: iins_mapper_lv2.get(i)),
				 iins_cate = 'CAR') 
	return m

def load_hth_data(paths_hth, paths_hth_ply, year, **kwargs):
	hth = load_data(paths_hth, year, usecols = ['ipolicy', 'assured_id', 'iins_kind'], **kwargs)
	hth_ply = load_data(path_hth_ply, year, usecols = ['ipolicy', 'applicant_id'])
	hth['iins_type'] = hth['iins_kind'].str.slice(0, 2)
	hth = hth.merge(hth_ply, on = 'ipolicy', how = 'left')\
			 .merge(pd.read_csv(PATH_HTH_CODE).dropna().rename(columns = {'åç¨±': 'iins_type_name', 'éšªåˆ¥': 'iins_type_cate'}),
			  		left_on = 'iins_type', right_on = 'ä»£ç¢¼', how = 'left')\
			 .rename(columns = {'assured_id': 'iassured', 'applicant_id': 'iapplicant'})\
			 .assign(iins_cate = 'HTH')
	return hth


# ------------------------------------------------------- #
# å„å¹´åº¦çš„é—œè¯å®¢æˆ¶ (å› ç‚ºè³‡æ–™å¤ªå¤§ï¼Œæ‹†å¹´åº¦åŸ·è¡Œ)
# ------------------------------------------------------- #
# %%
# load & prepare data
for year in range(2017, 2022):
	car = load_car_data(path_ply, path_iins, year)
	hth = load_hth_data(path_hth, path_hth_ply, year)
	# ======================================================= #
	# å°å¿ƒäº†ï¼Œæœ€å¾Œåšå‡ºä¾†çš„é—œè¯è¢«ä¿äººæœƒä¸çŸ¥é“æ˜¯å“ªå€‹éšªåˆ¥ä¾†çš„
	# ======================================================= #
	data = pd.concat([car, hth])

	hth_code = pd.read_csv(PATH_HTH_CODE).dropna().rename(columns = {'åç¨±': 'iins_type_name', 'éšªåˆ¥': 'iins_type_cate'})
	hth_code = hth_code.set_index('ä»£ç¢¼')['iins_type_name'].to_dict()
	with open(PATH_CAR_CODE_LV2, 'r', encoding = 'utf-8') as f:
		car_code = json.load(f)
	code_mapper = {**hth_code, **car_code}

	# build a graph
	data = data.query("iins_type_cate != 'åœ˜å‚·'")
	iapplicant = data['iapplicant'].unique()
	iassured = data['iassured'].unique()

	# %%
	# ---------------------------------------------------------------- #
	# é‡è¦ä¿æˆ¶:
	# æŠ•å½±çš„é„°å±…: è¢«ä¿äºº-->|è¦ä¿äºº|--è¢«ä¿äºº
	# æœ‰é—œä¿‚çš„å®¢æˆ¶ = åŸæœ¬çš„é„°å±….union(æŠ•å½±çš„é„°å±…)
	# ---------------------------------------------------------------- #
	G = nx.from_pandas_edgelist(data, source = 'iapplicant', target = 'iassured')#, create_using = nx.DiGraph)
	projected_G = nx.algorithms.bipartite.projected_graph(G, nodes = iassured)

	used_itag_ias = data.groupby('itag')['iassured'].nunique()
	used_itag_iap = data.groupby('itag')['iapplicant'].nunique()
	used_itag = set(used_itag_ias.index).union(used_itag_iap.index)
	data_usedTag = data.query("itag.isin(@used_itag)")
	iassured_tag = data_usedTag['iassured'].unique()
	G_tag = nx.from_pandas_edgelist(data_usedTag, source = 'itag', target = 'iassured')
	projected_GTag = nx.algorithms.bipartite.projected_graph(G_tag, nodes = iassured_tag)
	# %%
	nodes = pd.DataFrame([[set([j for j in G.neighbors(i) if j != i and isinstance(j, str)]) for i in iassured],
						  [set([j for j in projected_G.neighbors(i) if j != i and isinstance(j, str)]) for i in iassured],
						  [set([j for j in projected_GTag.neighbors(i) if j != i and isinstance(j, str)]) for i in iassured_tag],
						 ], columns = iassured, index = ['ç›´æ¥é€£æ¥', 'é€šéè¦ä¿', 'é€šéæ¨™çš„ç‰©']).T


	nodes = nodes.assign(num_original = lambda x: x['ç›´æ¥é€£æ¥'].apply(len),
						 num_byAppl = lambda x: x['é€šéè¦ä¿'].apply(len),
						 num_byTag = lambda x: x['é€šéæ¨™çš„ç‰©'].apply(lambda y: len(y) if y else 0))
	nodes['ç›´æ¥é€£æ¥'] = nodes['ç›´æ¥é€£æ¥'].apply(lambda x: ','.join(x) if x else '')
	nodes['é€šéè¦ä¿'] = nodes['é€šéè¦ä¿'].apply(lambda x: ','.join(x) if x else '')
	nodes['é€šéæ¨™çš„ç‰©'] = nodes['é€šéæ¨™çš„ç‰©'].apply(lambda x: ','.join(x) if x else '')


	# %%	
	profile = pd.read_parquet(PATH_PROFILE)
	profile = profile.groupby('id')[['plyAmt', 'clmAmt', 'ipolicy', 'clmed_iply']].sum()
	profile = profile.assign(clm_rate = lambda x: x['clmAmt'] / x['plyAmt'],
							 clm_ratio = lambda x: x['clmed_iply'] / x['ipolicy'])

	nodes = nodes.merge(profile, left_index = True, right_on = 'id', how ='left')

	nodes.sort_values('num_original', ascending = False, inplace = True)

	nodes.sort_values('num_byTag', ascending = False).to_parquet(os.path.join(PROJECT_PATH, f'2022 é—œè¯å®¢æˆ¶/data/{year}_é—œè¯å®¢æˆ¶.parq'), compression = 'brotli')
	nodes.sort_values('num_byTag', ascending = False).to_csv(os.path.join(PROJECT_PATH, f'2022 é—œè¯å®¢æˆ¶/data/{year}_é—œè¯å®¢æˆ¶.csv'))

# ------------------------------------------------------- #
# æŠŠæ¯å€‹äººå¤šå¹´çš„è³‡æ–™åˆæˆç‚ºä¸€ç­†:
# 1. é—œè¯å®¢æˆ¶ = å¤šå¹´ä¾†ç´¯ç©çš„ä¸é‡è¤‡é—œè¯å„æˆ¶ (i.e. å„å¹´çš„union)
# 2. ä¿è²»ã€è³ ä»˜ã€ä¿å–®ç­‰ = å¤šå¹´ä¾†çš„ç¸½å’Œ
# ------------------------------------------------------- #
# nodes.reset_index(inplace = True)
path_nodes_years = glob.glob(DIR_NODES_SAVED + '\\*_é—œè¯å®¢æˆ¶.parq')
nodes_years = pd.concat([pd.read_parquet(p) for p in path_nodes_years])
nodes_years.reset_index(inplace = True)
nodes_years.columns
def ids_union(ser):
	return set(','.join(ser).split(','))
nodes_years = nodes_years.groupby('index').agg({'ç›´æ¥é€£æ¥': ids_union,
												'é€šéè¦ä¿': ids_union,
												'é€šéæ¨™çš„ç‰©': ids_union,
												'plyAmt': sum,
												'clmAmt': sum,
												'ipolicy': sum,
												'clmed_iply': sum,
												})
nodes_years = nodes_years.assign(num_original = lambda x: x['ç›´æ¥é€£æ¥'].apply(len),
								 num_byAppl = lambda x: x['é€šéè¦ä¿'].apply(len),
								 num_byTag = lambda x: x['é€šéæ¨™çš„ç‰©'].apply(lambda y: len(y) if y else 0),
								 clm_rate = lambda x: x['clmAmt'] / x['plyAmt'],
								 clm_ratio = lambda x: x['clmed_iply'] / x['ipolicy'])

nodes_years.to_parquet(os.path.join(PROJECT_PATH, f'2022 é—œè¯å®¢æˆ¶/data/ä¸åˆ†å¹´/é—œè¯å®¢æˆ¶.parq'), compression = 'brotli')


# ------------------------------------------------------- #
# ç‚ºä¸åŒæ–¹æ³•æ‰¾åˆ°çš„é—œè¯å®¢æˆ¶ï¼Œè¨ˆç®—çµ±è¨ˆé‡ã€‚ç”¨ä¾†è¡¡é‡å’ŒæŒ‡å®šäººç›¸é—œçš„ä¸€ç¾¤äººæ˜¯å¦éœ€è¦è­¦æˆ’
# e.g. å‡è¨­å°æ˜ç›´æ¥é—œè¯çš„æœ‰10å€‹äººï¼Œé€™10å€‹äººçš„æç‡ç­‰ç­‰çµ±è¨ˆé‡
# ------------------------------------------------------- #

# index = set(nodes_years.index)
# def row_stats(connected_group: list, cols = ['plyAmt', 'clmAmt', 'ipolicy', 'clmed_iply']):
# 	# res = nodes.query("index.isin(@connected_group)")[['plyAmt', 'clmAmt', 'ipolicy', 'clmed_iply']].sum()
# 	connected_group = index.intersection(connected_group)
# 	res = nodes_years.loc[connected_group][['plyAmt', 'clmAmt', 'ipolicy', 'clmed_iply']].sum()
# 	res['clm_rate'] = res['clmAmt'] / res['plyAmt']
# 	res['clm_ratio'] = res['clmed_iply'] / res['ipolicy']
# 	return res

# gp_stats_1 = nodes_years['ç›´æ¥é€£æ¥'].apply(row_stats)
# gp_stats_1.to_parquet(os.path.join(PROJECT_PATH, f'2022 é—œè¯å®¢æˆ¶/data/ä¸åˆ†å¹´/é—œè¯å®¢æˆ¶_gpçµ±è¨ˆ_ç›´æ¥é€£æ¥.parq'), compression = 'brotli')

# gp_stats_1 = nodes_years['é€šéè¦ä¿'].apply(row_stats)
# gp_stats_1.to_parquet(os.path.join(PROJECT_PATH, f'2022 é—œè¯å®¢æˆ¶/data/ä¸åˆ†å¹´/é—œè¯å®¢æˆ¶_gpçµ±è¨ˆ_é€šéè¦ä¿.parq'), compression = 'brotli')

# gp_stats_1 = nodes_years['é€šéæ¨™çš„ç‰©'].apply(row_stats)
# gp_stats_1.to_parquet(os.path.join(PROJECT_PATH, f'2022 é—œè¯å®¢æˆ¶/data/ä¸åˆ†å¹´/é—œè¯å®¢æˆ¶_gpçµ±è¨ˆ_é€šéæ¨™çš„ç‰©.parq'), compression = 'brotli')

# ------------------------------------------------------- #
# æŠŠä¸åˆ†å¹´çš„é—œè¯å®¢æˆ¶ left join é—œè¯å®¢æˆ¶_gpçµ±è¨ˆ
# ------------------------------------------------------- #
nodes_years = pd.read_parquet(os.path.join(PROJECT_PATH, '2022 é—œè¯å®¢æˆ¶/data/ä¸åˆ†å¹´/é—œè¯å®¢æˆ¶.parq'))
for gp in ['ç›´æ¥é€£æ¥', 'é€šéæ¨™çš„ç‰©', 'é€šéè¦ä¿']:
	gp_data = pd.read_parquet(os.path.join(PROJECT_PATH, f'2022 é—œè¯å®¢æˆ¶/data/ä¸åˆ†å¹´/é—œè¯å®¢æˆ¶_gpçµ±è¨ˆ_{gp}.parq'))
	gp_data.columns = [f'{c}_{gp}' for c in gp_data.columns]
	nodes_years = nodes_years.merge(gp_data, left_index = True, right_index = True, how = 'left')
nodes_years.iloc[:, 3:].to_parquet(os.path.join(PROJECT_PATH, '2022 é—œè¯å®¢æˆ¶/data/ä¸åˆ†å¹´/é—œè¯å®¢æˆ¶_prepared.parq'), compression = 'brotli')
nodes_years.iloc[:, 3:].to_csv(os.path.join(PROJECT_PATH, '2022 é—œè¯å®¢æˆ¶/data/ä¸åˆ†å¹´/é—œè¯å®¢æˆ¶_prepared.csv'), sep = '|')

# ------------------------------------------------------- #
# åˆ†æ
# ------------------------------------------------------- #
nodes_years.iloc[:, 3:].sort_values(['num_original', 'clm_rate'], ascending = False)\
		   .head(10)\
		   .to_markdown(os.path.join(PROJECT_PATH, '2022 é—œè¯å®¢æˆ¶/data/tops/ç›´æ¥é€£çµtops.txt'))

nodes_years.iloc[:, 3:].sort_values(['num_byAppl', 'clm_rate'], ascending = False)\
		   .head(10)\
		   .to_markdown(os.path.join(PROJECT_PATH, '2022 é—œè¯å®¢æˆ¶/data/tops/é€éè¦ä¿tops.txt'))

nodes_years.iloc[:, 3:].sort_values(['num_byTag', 'clm_rate'], ascending = False)\
		   .head(10)\
		   .to_markdown(os.path.join(PROJECT_PATH, '2022 é—œè¯å®¢æˆ¶/data/tops/é€éæ¨™çš„ç‰©tops.txt'))



row_stats = profile.loc[row['ç›´æ¥é€£æ¥'].split(',')][['plyAmt', 'clmAmt', 'ipolicy', 'clmed_iply']].sum()\
		.assign(clm_rate = lambda x: x['clmAmt'] / x['plyAmt'],
				clm_ratio = lambda x: x['clmed_iply'] / x['ipolicy'])
# %%

# %%
# èªªæ˜ç”¨åœ–
import matplotlib.pyplot as plt

G_t = nx.Graph()
G_t.add_edges_from([('1', '1'), ('1', '3'), ('2', '3')])
pos = graphviz_layout(G_t, prog=r'D:\Graphviz\bin\twopi.exe')
G_t.nodes()

fig, ax = plt.subplots()
nx.draw_networkx_edges(
    G_t,
    pos=pos,
    ax=ax,
    arrows=True,
    arrowstyle="-",
    min_source_margin=5,
    min_target_margin=5,
)









import plotly.graph_objects as go
import plotly.offline as pyo


G_t = nx.Graph()
G_t.add_edges_from([(1, 1), (1, 3), (2, 3)])
type_icon = {'iappl': 'ğŸ™‹<br>è¦ä¿äºº', 'iassured': 'ğŸ‘±<br>è¢«ä¿äºº', 'car': 'ğŸš—'}
nx.set_node_attributes(G_t, {1: {'type': 'iassured'}, 
							 2: {'type': 'iassured'}, 
							 3: {'type': 'iappl'}
							 })
pos = np.array([(0, 0), (.5, .5), (1, 0)])

nodes = go.Scatter(
			x = pos[:, 0],
			y = pos[:, 1],
			text = [type_icon.get(n[1]['type']) for n in G_t.nodes(data = True)],
			mode = 'text',
			textfont = {'size': 20}
		)

connections = []
for e in G_t.edges():
	e
	t = go.Scatter(
					x = pos[e],
					y = pos[:, 1],
					text = [type_icon.get(n[1]['type']) for n in G_t.nodes(data = True)],
					mode = 'text',
					textfont = {'size': 20}
				)

pyo.plot(go.Figure([nodes]), auto_open = False)


G_t.nodes()[1]

G_t_p = nx.algorithms.bipartite.projected_graph(G_t, nodes = [1, 2, 3])
nx.draw(G_t, with_labels = True)
nx.draw(G_t_p, with_labels = True)




for x in nodes['ç›´æ¥é€£æ¥']:
	','.join(x) if x else ''